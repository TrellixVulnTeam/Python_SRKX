{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDACITY PROJECT 4 - WRANGLE AND ANALYZE DATA\n",
    "## DOG TWITTER DATA ANALYSIS \n",
    "### *Jhonatan Nagasako*\n",
    "#### *24-FEB-2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='contents'></a>\n",
    "# Table of Contents\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#intro\">A. INTRODUCTION</a></li>\n",
    "<li><a href=\"#scope\">B. PROJECT MOTIVATION-SCOPE</a></li>\n",
    "<li><a href=\"#gather\">1. GATHERING DATA</a></li>\n",
    "<li><a href=\"#assess\">2. ASSESSING DATA</a></li>\n",
    "<li><a href=\"#clean\">3. CLEANING DATA</a></li>\n",
    "<li><a href=\"#store\">4. STORING AND ACTING ON WRANGLED DATA</a></li>\n",
    "<li><a href=\"#report\">5. REPORT-DISCUSSION-CONCLUSION</a></li>\n",
    "<li><a href=\"#files\">6. PROJECT FILES</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='intro'></a>\n",
    "# A. INTRODUCTION\n",
    "\n",
    "Real-world data rarely comes clean. Using Python and its libraries, data was gathered from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. Data wrangling efforts was documented in a Jupyter Notebook, which was then showcased  through analyses and visualizations using Python (and its libraries) and/or SQL.\n",
    "\n",
    "The dataset that used for wrangling (and analyzing and visualizing) is the tweet archive of Twitter user [@dog_rates](https://twitter.com/dog_rates), also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent). WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "WeRateDogs [downloaded their Twitter archive](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive) and sent it to Udacity via email exclusively for you to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon.\n",
    "\n",
    "\n",
    "![dog and twitter](https://video.udacity-data.com/topher/2017/October/59dd378f_dog-rates-social/dog-rates-social.jpg)\n",
    "\n",
    "*Image via [Boston Magazine](https://www.bostonmagazine.com/arts-entertainment/2017/04/18/dog-rates-mit/)*\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scope'></a>\n",
    "# B. Project Motivation\n",
    "## Context\n",
    "The goal: wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n",
    "\n",
    "## The Data\n",
    "### Enhanced Twitter Archive\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, I have filtered for tweets with ratings only (there are 2356).\n",
    "\n",
    "![table of tweets analyzed](https://video.udacity-data.com/topher/2017/October/59dd4791_screenshot-2017-10-10-18.19.36/screenshot-2017-10-10-18.19.36.png)\n",
    "*The extracted data from each tweet's text*\n",
    "\n",
    "### Extracted data from tweet text\n",
    "The extracted data from each tweet's text\n",
    "\n",
    "This provided data set was extracted programmatically, but more processing (e.g., cleaning and tyding) is requried. The ratings probably aren't all correct. Same goes for the dog names and probably dog stages (see below for more information on these) too. As stated before more data processing is required to assess and clean these columns for later analysis and visualization.\n",
    "\n",
    "![dog dictionary](https://video.udacity-data.com/topher/2017/October/59e04ceb_dogtionary-combined/dogtionary-combined.png)\n",
    "*The Dogtionary explains the various stages of dog: doggo, pupper, puppo, and floof(er) (via the [#WeRateDogs book on Amazon](https://www.amazon.com/WeRateDogs-Most-Hilarious-Adorable-Youve/dp/1510717145))*\n",
    "\n",
    "### Additional Data via the Twitter API\n",
    "\n",
    "Back to the basic-ness of Twitter archives: retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API. Well, \"anyone\" who has access to data for the 3000 most recent tweets, at least. The WeRateDogs Twitter archive and specifically the tweet IDs within it, can gather this data for all 5000+. The Twitter's API was used to query this valuable data. \n",
    "\n",
    "**Please note that the Twitter API was NOT utilized for this project for data securty/privacy reasons. This data was provided for the scope of this project.**\n",
    "\n",
    "### Image Predictions File\n",
    "\n",
    "One more cool thing: Every image in the WeRateDogs Twitter archive was processed through a [neural network](https://www.youtube.com/watch?v=2-Ol7ZB0MmU) that can classify breeds of dogs* (provided by project). The results: a table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "\n",
    "![tweet image prediction](https://video.udacity-data.com/topher/2017/October/59dd4d2c_screenshot-2017-10-10-18.43.41/screenshot-2017-10-10-18.43.41.png)\n",
    "*Tweet image prediction data*\n",
    "\n",
    "### Image predictions\n",
    "Tweet image prediction data\n",
    "\n",
    "So for the last row in that table:\n",
    "\n",
    "tweet_id is the last part of the tweet URL after \"status/\" → https://twitter.com/dog_rates/status/889531135344209921\n",
    "* p1 is the algorithm's #1 prediction for the image in the tweet → **golden retriever**\n",
    "* p1_conf is how confident the algorithm is in its #1 prediction → **95%**\n",
    "* p1_dog is whether or not the #1 prediction is a breed of dog → **TRUE**\n",
    "* p2 is the algorithm's second most likely prediction → **Labrador retriever**\n",
    "* p2_conf is how confident the algorithm is in its #2 prediction → **1%**\n",
    "* p2_dog is whether or not the #2 prediction is a breed of dog → **TRUE**\n",
    "* etc.\n",
    "\n",
    "And the #1 prediction for the image in that tweet was spot on:\n",
    "\n",
    "@dog_rates tweet\n",
    "![gold retriever](https://video.udacity-data.com/topher/2017/October/59dd4e05_dog-pred/dog-pred.png)\n",
    "*A golden retriever named Stuart*\n",
    "\n",
    "So that's all fun and good. But all of this additional data will need to be gathered, assessed, and cleaned--which is the scope of this project\n",
    "\n",
    "## Key Points\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    "* Only use original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html).\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* It is not required to gather tweets beyond August 1st, 2017 because it is out of scope. Image predictions cannot be gathered for new tweet data after this date because the source file for the image prediction is not provided--again out of scope for this project\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='gather'></a>\n",
    "# 1. GATHERING DATA\n",
    "\n",
    "<font color=blue>\n",
    "\n",
    "## Gathering Data - Set 1 Requirements\n",
    "**1.1 CRITERIA:** The student is able to gather data from a variety of sources and file formats.\n",
    "\n",
    "**1.1 SPECIFICATION:**\n",
    "Data is successfully gathered:\n",
    "* From at least the three (3) different sources on the Project Details page.\n",
    "* In at least the three (3) different file formats on the Project Details page.\n",
    "\n",
    "Each piece of data is imported into a separate pandas DataFrame at first.\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for all of the packages used for analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm;\n",
    "\n",
    "# package required to get images from twitter data\n",
    "import requests\n",
    "\n",
    "# package required to access json file\n",
    "import json\n",
    "\n",
    "\n",
    "# Remember to include a 'magic word' so that your visualizations are plotted\n",
    "#   inline with the notebook. See this page for more:\n",
    "#   http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Specification 1 - data provided (e.g., via flashdrive)\n",
    "\n",
    "<a href=\"#gather\">[Gathering Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  \n",
       "1                  10    Tilly  None    None   None  None  \n",
       "2                  10   Archie  None    None   None  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather Specification 1 - file given (file provided via flashdrive)\n",
    "df_archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_archive.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Specification 2 - data accessed by internet via Requests library\n",
    "\n",
    "<a href=\"#gather\">[Gathering Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather Specification 2 - access via internet to get images for predictions, accessed programmatically\n",
    "# https://pypi.org/project/requests/\n",
    "\n",
    "# note that running this code will generate the file \"image_prediction.tsv\"\n",
    "\n",
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv',\n",
    "                auth=('user','pass'))\n",
    "\n",
    "# better check status and \n",
    "assert r.status_code == 200, 'Request corruption detected, status code is supposed to be 200 (aka \"HTTP OK Success\")'\n",
    "assert r.encoding == 'utf-8', 'Request corruption detected, encoding was NOT \\'utf-8\\' (will cause issues later in json coding)'\n",
    "\n",
    "open('image_prediction.tsv', 'wb').write(r.content)\n",
    "df_prediction = pd.read_csv('image_prediction.tsv', sep='\\t')\n",
    "df_prediction.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Specification 3 - data accessed by internet via Twitter API Tweepy\n",
    "\n",
    "<a href=\"#gather\">[Gathering Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>8853</td>\n",
       "      <td>39467</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>6514</td>\n",
       "      <td>33819</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>4328</td>\n",
       "      <td>25461</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  retweet_count  favorite_count  \\\n",
       "0  892420643555336193           8853           39467   \n",
       "1  892177421306343426           6514           33819   \n",
       "2  891815181378084864           4328           25461   \n",
       "\n",
       "                                           full_text  \n",
       "0  This is Phineas. He's a mystical boy. Only eve...  \n",
       "1  This is Tilly. She's just checking pup on you....  \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather Specification 3 - json file\n",
    "# https://stackoverflow.com/questions/47612822/how-to-create-pandas-dataframe-from-twitter-search-api\n",
    "twitter_list =[]\n",
    "\n",
    "with open('tweet-json.txt', encoding='utf-8') as json_file:\n",
    "    for each_dictionary in json_file:   \n",
    "        \n",
    "        tweets_dict = {} # the dictionary terms are stored here\n",
    "        tweets_json = json.loads(each_dictionary)\n",
    "        \n",
    "        tweets_dict['tweet_id'] = tweets_json['id_str']\n",
    "        tweets_dict['retweet_count'] = tweets_json['retweet_count']\n",
    "        tweets_dict['favorite_count'] = tweets_json['favorite_count']\n",
    "        tweets_dict['full_text'] = tweets_json['full_text']\n",
    "        \n",
    "        twitter_list.append(tweets_dict)\n",
    "\n",
    "# write to dataframe\n",
    "df_twitter = pd.DataFrame(twitter_list)\n",
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**_Code below is required to programically interface and gather data from TWITTER using the ```Tweepy``` API. However, I used the provided file instead because I do NOT want to create Twitter account for cyber securty/privacy reasons._**\n",
    "\n",
    "<font color='blue'>\n",
    "             \n",
    "> Essentially, you will run the Twitter API with will get you a JSON file (code block below). This JSON file will then be read using Python to get the ```tweet-json.txt``` used in the code block above. \n",
    "\n",
    "\n",
    "```\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df_1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Gathering Data Section\n",
    "\n",
    "<a href=\"#gather\">[Gathering Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='assess'></a>\n",
    "# 2. ASSESSING DATA\n",
    "\n",
    "<font color=blue>\n",
    "\n",
    "**2.1 CRITERIA:** The student is able to assess data visually and programmatically for quality and tidiness.\n",
    "\n",
    "**2.1 SPECIFICATION:**\n",
    "Two types of assessment are used:\n",
    "\n",
    "* Visual assessment: each piece of gathered data is displayed in the Jupyter Notebook for visual assessment purposes. Once displayed, data can additionally be assessed in an external application (e.g. Excel, text editor).\n",
    "* Programmatic assessment: pandas' functions and/or methods are used to assess the data.\n",
    "\n",
    "---\n",
    "\n",
    "**2.2 CRITERIA:** The student is able to thoroughly assess a dataset.\n",
    "\n",
    "**2.2 SPECIFICATION:**\n",
    "At least eight (8) data quality issues and two (2) tidiness issues are detected, and include the issues to clean to satisfy the Project Motivation. Each issue is documented in one to a few sentences each.\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Specification 2.1 - Assessing data visual assessment (e.g., via CSV)\n",
    "\n",
    "* Visual assessment: each piece of gathered data is displayed in the Jupyter Notebook for visual assessment purposes. Once displayed, data can additionally be assessed in an external application (e.g. Excel, text editor).\n",
    "\n",
    "<a href=\"#assess\">[Assessing Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current dataframes active from **_Section 1. GATHER_**\n",
    "1. ```df_archive``` = tweet metadata\n",
    "2. ```df_prediction``` = tweet picture prediction\n",
    "3. ```df_twitter``` = tweet retweet_count, favorite_count, and full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual assessment - warning to user that opening these files \"may\" cause viewing software to crash\n",
    "# help: https://www.guru99.com/python-check-if-file-exists.html\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "fileFlag = False # initilized as FALSE -- assuming .csv files have not be created from dataframes in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files aready created! ... Ready for user VISUAL assessment\n"
     ]
    }
   ],
   "source": [
    "# help: https://www.geeksforgeeks.org/g-fact-41-multiple-return-values-in-python/\n",
    "def createCSV():\n",
    "    # adding \"1-\" for easier file handling in folder\n",
    "    df_archive.to_csv('1-archive.csv')\n",
    "    df_prediction.to_csv('1-prediction.csv')\n",
    "    df_twitter.to_csv('1-twitter.csv')\n",
    "    fileFlag = True\n",
    "    print('.csv Files created ... Ready for user VISUAL assessment')\n",
    "    return fileFlag\n",
    "\n",
    "if path.exists('1-archive.csv') == True and path.exists('1-prediction.csv') == True and path.exists('1-twitter.csv') == True:\n",
    "    print(\"Files aready created! ... Ready for user VISUAL assessment\")\n",
    "elif fileFlag == False:\n",
    "    fileFlag = createCSV() # Assign returned tuple , execute file create assuming fileFlag is FALSE (has not be done)\n",
    "else:\n",
    "    assert path.exists('1-archive.csv') == True, \"You need to create the 1-archive.csv file\"\n",
    "    assert path.exists('1-prediction.csv') == True, \"You need to create the 1-prediction.csv file\"\n",
    "    assert path.exists('1-twitter.csv') == True, \"You need to create the 1-twitter.csv file\"\n",
    "    print(\"Files exists! ... Ready for user VISUAL assessment\")\n",
    "\n",
    "# could add button here for \"confirmation\" data was reviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Specification 2.1 - Assessing data PROGRAMMICALLY assessment (e.g., via CSV)\n",
    "\n",
    "* Programmatic assessment: pandas' functions and/or methods are used to assess the data.\n",
    "\n",
    "<a href=\"#assess\">[Assessing Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmically assessment of data\n",
    "\n",
    "#import the newly created .csv files\n",
    "df_archive = pd.read_csv('1-archive.csv')\n",
    "df_prediction = pd.read_csv('1-prediction.csv')\n",
    "df_twitter = pd.read_csv('1-twitter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "Review ```df_archive``` data programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0           0  892420643555336193                    NaN                  NaN   \n",
       "1           1  892177421306343426                    NaN                  NaN   \n",
       "2           2  891815181378084864                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  \n",
       "1                  10    Tilly  None    None   None  None  \n",
       "2                  10   Archie  None    None   None  None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_archive.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  2356 non-null   int64  \n",
      " 1   tweet_id                    2356 non-null   int64  \n",
      " 2   in_reply_to_status_id       78 non-null     float64\n",
      " 3   in_reply_to_user_id         78 non-null     float64\n",
      " 4   timestamp                   2356 non-null   object \n",
      " 5   source                      2356 non-null   object \n",
      " 6   text                        2356 non-null   object \n",
      " 7   retweeted_status_id         181 non-null    float64\n",
      " 8   retweeted_status_user_id    181 non-null    float64\n",
      " 9   retweeted_status_timestamp  181 non-null    object \n",
      " 10  expanded_urls               2297 non-null   object \n",
      " 11  rating_numerator            2356 non-null   int64  \n",
      " 12  rating_denominator          2356 non-null   int64  \n",
      " 13  name                        2356 non-null   object \n",
      " 14  doggo                       2356 non-null   object \n",
      " 15  floofer                     2356 non-null   object \n",
      " 16  pupper                      2356 non-null   object \n",
      " 17  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(4), object(10)\n",
      "memory usage: 331.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "Review ```df_prediction``` data programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id  \\\n",
       "0           0  666020888022790149   \n",
       "1           1  666029285002620928   \n",
       "2           2  666033412701032449   \n",
       "\n",
       "                                           jpg_url  img_num  \\\n",
       "0  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg        1   \n",
       "1  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg        1   \n",
       "2  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg        1   \n",
       "\n",
       "                       p1   p1_conf  p1_dog                  p2   p2_conf  \\\n",
       "0  Welsh_springer_spaniel  0.465074    True              collie  0.156665   \n",
       "1                 redbone  0.506826    True  miniature_pinscher  0.074192   \n",
       "2         German_shepherd  0.596461    True            malinois  0.138584   \n",
       "\n",
       "   p2_dog                   p3   p3_conf  p3_dog  \n",
       "0    True    Shetland_sheepdog  0.061428    True  \n",
       "1    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2    True           bloodhound  0.116197    True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  2075 non-null   int64  \n",
      " 1   tweet_id    2075 non-null   int64  \n",
      " 2   jpg_url     2075 non-null   object \n",
      " 3   img_num     2075 non-null   int64  \n",
      " 4   p1          2075 non-null   object \n",
      " 5   p1_conf     2075 non-null   float64\n",
      " 6   p1_dog      2075 non-null   bool   \n",
      " 7   p2          2075 non-null   object \n",
      " 8   p2_conf     2075 non-null   float64\n",
      " 9   p2_dog      2075 non-null   bool   \n",
      " 10  p3          2075 non-null   object \n",
      " 11  p3_conf     2075 non-null   float64\n",
      " 12  p3_dog      2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(3), object(4)\n",
      "memory usage: 168.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_prediction.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "Review ```df_twitter``` data programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>8853</td>\n",
       "      <td>39467</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>6514</td>\n",
       "      <td>33819</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>4328</td>\n",
       "      <td>25461</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id  retweet_count  favorite_count  \\\n",
       "0           0  892420643555336193           8853           39467   \n",
       "1           1  892177421306343426           6514           33819   \n",
       "2           2  891815181378084864           4328           25461   \n",
       "\n",
       "                                           full_text  \n",
       "0  This is Phineas. He's a mystical boy. Only eve...  \n",
       "1  This is Tilly. She's just checking pup on you....  \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2354 entries, 0 to 2353\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      2354 non-null   int64 \n",
      " 1   tweet_id        2354 non-null   int64 \n",
      " 2   retweet_count   2354 non-null   int64 \n",
      " 3   favorite_count  2354 non-null   int64 \n",
      " 4   full_text       2354 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 92.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Specification 2.2 - Identify data quality and tidiness issues and steps for cleaning\n",
    "\n",
    "* At least eight (8) data quality issues and two (2) tidiness issues are detected, and include the issues to clean to satisfy the Project Motivation. Each issue is documented in one to a few sentences each.\n",
    "\n",
    "**Tips for Tidying**\n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table\n",
    "*Reference for [tidy data here](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)*\n",
    "\n",
    "**Tips for Common Data Quality Issues**\n",
    "1. Missing data\n",
    "2. Invalide data (e.g., state a negative height, or other datatype validation errors--str vs int vs float, think there can only be 2 people in a room... not 2.54 people in a room... *unless there's ghosts lol*)\n",
    "3. Inaccurate data (e.g., specifying a foot = 5 inches, which is WRONG. A foot = 12 inches)\n",
    "4. Inconsistent data (e.g., mixing up units, some data captured as cm instead of inches)\n",
    "\n",
    "<a href=\"#assess\">[Assessing Data Requirements]</a> <a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  2356 non-null   int64  \n",
      " 1   tweet_id                    2356 non-null   int64  \n",
      " 2   in_reply_to_status_id       78 non-null     float64\n",
      " 3   in_reply_to_user_id         78 non-null     float64\n",
      " 4   timestamp                   2356 non-null   object \n",
      " 5   source                      2356 non-null   object \n",
      " 6   text                        2356 non-null   object \n",
      " 7   retweeted_status_id         181 non-null    float64\n",
      " 8   retweeted_status_user_id    181 non-null    float64\n",
      " 9   retweeted_status_timestamp  181 non-null    object \n",
      " 10  expanded_urls               2297 non-null   object \n",
      " 11  rating_numerator            2356 non-null   int64  \n",
      " 12  rating_denominator          2356 non-null   int64  \n",
      " 13  name                        2356 non-null   object \n",
      " 14  doggo                       2356 non-null   object \n",
      " 15  floofer                     2356 non-null   object \n",
      " 16  pupper                      2356 non-null   object \n",
      " 17  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(4), object(10)\n",
      "memory usage: 331.4+ KB\n",
      "______________________________________________________________\n",
      "\n",
      "prediction data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  2075 non-null   int64  \n",
      " 1   tweet_id    2075 non-null   int64  \n",
      " 2   jpg_url     2075 non-null   object \n",
      " 3   img_num     2075 non-null   int64  \n",
      " 4   p1          2075 non-null   object \n",
      " 5   p1_conf     2075 non-null   float64\n",
      " 6   p1_dog      2075 non-null   bool   \n",
      " 7   p2          2075 non-null   object \n",
      " 8   p2_conf     2075 non-null   float64\n",
      " 9   p2_dog      2075 non-null   bool   \n",
      " 10  p3          2075 non-null   object \n",
      " 11  p3_conf     2075 non-null   float64\n",
      " 12  p3_dog      2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(3), object(4)\n",
      "memory usage: 168.3+ KB\n",
      "______________________________________________________________\n",
      "\n",
      "twitter data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2354 entries, 0 to 2353\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      2354 non-null   int64 \n",
      " 1   tweet_id        2354 non-null   int64 \n",
      " 2   retweet_count   2354 non-null   int64 \n",
      " 3   favorite_count  2354 non-null   int64 \n",
      " 4   full_text       2354 non-null   object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 92.1+ KB\n",
      "______________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another look at the data, determine what cleaning steps are required\n",
    "print('archive data\\n')\n",
    "df_archive.info()\n",
    "print('______________________________________________________________\\n')\n",
    "\n",
    "print('prediction data\\n')\n",
    "df_prediction.info()\n",
    "print('______________________________________________________________\\n')\n",
    "\n",
    "print('twitter data\\n')\n",
    "df_twitter.info()\n",
    "print('______________________________________________________________\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any duplicated records in df_archive? --> 0\n",
      "Any duplicated records in df_prediction? -->  0\n",
      "Any duplicated records in df_twitter? -->  0\n"
     ]
    }
   ],
   "source": [
    "print('Any duplicated records in df_archive? -->', df_archive.duplicated().sum())\n",
    "print('Any duplicated records in df_prediction? --> ', df_prediction.duplicated().sum())\n",
    "print('Any duplicated records in df_twitter? --> ',df_twitter.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing records in df_archive?\n",
      " Unnamed: 0                       0\n",
      "tweet_id                         0\n",
      "in_reply_to_status_id         2278\n",
      "in_reply_to_user_id           2278\n",
      "timestamp                        0\n",
      "source                           0\n",
      "text                             0\n",
      "retweeted_status_id           2175\n",
      "retweeted_status_user_id      2175\n",
      "retweeted_status_timestamp    2175\n",
      "expanded_urls                   59\n",
      "rating_numerator                 0\n",
      "rating_denominator               0\n",
      "name                             0\n",
      "doggo                            0\n",
      "floofer                          0\n",
      "pupper                           0\n",
      "puppo                            0\n",
      "dtype: int64\n",
      "\n",
      "Any missing records in df_prediction?\n",
      " Unnamed: 0    0\n",
      "tweet_id      0\n",
      "jpg_url       0\n",
      "img_num       0\n",
      "p1            0\n",
      "p1_conf       0\n",
      "p1_dog        0\n",
      "p2            0\n",
      "p2_conf       0\n",
      "p2_dog        0\n",
      "p3            0\n",
      "p3_conf       0\n",
      "p3_dog        0\n",
      "dtype: int64\n",
      "\n",
      "Any missing records in df_twitter?\n",
      " Unnamed: 0        0\n",
      "tweet_id          0\n",
      "retweet_count     0\n",
      "favorite_count    0\n",
      "full_text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Any missing records in df_archive?\\n', df_archive.isnull().sum())\n",
    "print('\\nAny missing records in df_prediction?\\n', df_prediction.isnull().sum())\n",
    "print('\\nAny missing records in df_twitter?\\n',df_twitter.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    2356\n",
       "tweet_id                      2356\n",
       "in_reply_to_status_id           77\n",
       "in_reply_to_user_id             31\n",
       "timestamp                     2356\n",
       "source                           4\n",
       "text                          2356\n",
       "retweeted_status_id            181\n",
       "retweeted_status_user_id        25\n",
       "retweeted_status_timestamp     181\n",
       "expanded_urls                 2218\n",
       "rating_numerator                40\n",
       "rating_denominator              18\n",
       "name                           957\n",
       "doggo                            2\n",
       "floofer                          2\n",
       "pupper                           2\n",
       "puppo                            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('archive data\\n')\n",
    "df_archive.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    2075\n",
       "tweet_id      2075\n",
       "jpg_url       2009\n",
       "img_num          4\n",
       "p1             378\n",
       "p1_conf       2006\n",
       "p1_dog           2\n",
       "p2             405\n",
       "p2_conf       2004\n",
       "p2_dog           2\n",
       "p3             408\n",
       "p3_conf       2006\n",
       "p3_dog           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction data\\n')\n",
    "df_prediction.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        2354\n",
       "tweet_id          2354\n",
       "retweet_count     1724\n",
       "favorite_count    2007\n",
       "full_text         2354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('twitter data\\n')\n",
    "df_twitter.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2356.0\n",
       "mean        inf\n",
       "std         NaN\n",
       "min         0.0\n",
       "25%       100.0\n",
       "50%       110.0\n",
       "75%       120.0\n",
       "max         inf\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick looks at statis to determine spread to eliminate outliers\n",
    "ratings_level = 100*(df_archive.rating_numerator / df_archive.rating_denominator)\n",
    "ratings_level\n",
    "ratings_level.describe()\n",
    "\n",
    "# so, lets make the cut-off point for exceedingly high levels of ratings be 120%... \n",
    "# but that deletes over 400 records... so lets say 150% then! Only 12 records removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2.354000e+03</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1176.500000</td>\n",
       "      <td>7.426978e+17</td>\n",
       "      <td>3164.797366</td>\n",
       "      <td>8080.968564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>679.685589</td>\n",
       "      <td>6.852812e+16</td>\n",
       "      <td>5284.770364</td>\n",
       "      <td>11814.771334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.660209e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>588.250000</td>\n",
       "      <td>6.783975e+17</td>\n",
       "      <td>624.500000</td>\n",
       "      <td>1415.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1176.500000</td>\n",
       "      <td>7.194596e+17</td>\n",
       "      <td>1473.500000</td>\n",
       "      <td>3603.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1764.750000</td>\n",
       "      <td>7.993058e+17</td>\n",
       "      <td>3652.000000</td>\n",
       "      <td>10122.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2353.000000</td>\n",
       "      <td>8.924206e+17</td>\n",
       "      <td>79515.000000</td>\n",
       "      <td>132810.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      tweet_id  retweet_count  favorite_count\n",
       "count  2354.000000  2.354000e+03    2354.000000     2354.000000\n",
       "mean   1176.500000  7.426978e+17    3164.797366     8080.968564\n",
       "std     679.685589  6.852812e+16    5284.770364    11814.771334\n",
       "min       0.000000  6.660209e+17       0.000000        0.000000\n",
       "25%     588.250000  6.783975e+17     624.500000     1415.000000\n",
       "50%    1176.500000  7.194596e+17    1473.500000     3603.500000\n",
       "75%    1764.750000  7.993058e+17    3652.000000    10122.250000\n",
       "max    2353.000000  8.924206e+17   79515.000000   132810.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the stats of retweets and favorites to understand spread to remove \"zero\" values\n",
    "df_twitter.describe()\n",
    "\n",
    "# actually, lets not remove anything, this is data from Twitter database, \n",
    "# these \"zero\" because low probability that they were mistakes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "## QUALITY\n",
    "    \n",
    "✔️ 1. all dataframes --> Remove missing data column ```Unnamed: 0```\n",
    "\n",
    "2. Missing data, Drop columns:\n",
    "    * df_archive\n",
    "        * in_reply_to_status_id\n",
    "        * in_reply_to_user_id\n",
    "        * retweeted_status_id\n",
    "        * retweeted_status_user_id\n",
    "        * retweeted_status_timestamp\n",
    "        * expanded_urls \n",
    "        * in_reply_to_status_id\n",
    "        * in_reply_to_user_id \n",
    "    \n",
    "3. df_archive --> convert columns to boolean for easier analysis\n",
    "    * doggo\n",
    "    * floofer\n",
    "    * pupper\n",
    "    * puppo\n",
    "\n",
    "4. df_archive --> convert form object to in64\n",
    "    * doggo\n",
    "    * floofer\n",
    "    * pupper\n",
    "    * puppo\n",
    "    \n",
    "5. df_archive --> need for classification of ```floof``` for dogs that did not meeting the four listed catagories below:\n",
    "    * doggo\n",
    "    * floofer\n",
    "    * pupper\n",
    "    * puppo\n",
    "    \n",
    "6. df_archive --> remove entries with EXTREME ratings outliers (anything above 150%). Those entries are: \n",
    "    * 55 with 170%\n",
    "    * 188 with 4200%\n",
    "    * 189 with 6660%\n",
    "    * 290 with 1820%\n",
    "    * 340 with 750%\n",
    "    * 516 with 343%\n",
    "    * 695 with 750%\n",
    "    * 763 with 270%\n",
    "    * 979 with 17760% wow!\n",
    "    * 1712 with 260%\n",
    "    * 2074 with 4200%\n",
    "\n",
    "7. df_archive --> remove entry 313 because no denominator is provided (entered as 0)\n",
    "\n",
    "8. df_prediction --> make all names of dogs CAPITALIZED, to prevent any variants of different capitilizations\n",
    "\n",
    "*At least eight (8) data quality issues and two (2) tidiness issues are detected, and include the issues to clean to satisfy the Project Motivation. Each issue is documented in one to a few sentences each.*\n",
    "    \n",
    "**Tips for Common Data Quality Issues**\n",
    "1. Missing data\n",
    "2. Invalide data (e.g., state a negative height, or other datatype validation errors--str vs int vs float, think there can only be 2 people in a room... not 2.54 people in a room... *unless there's ghosts lol*)\n",
    "3. Inaccurate data (e.g., specifying a foot = 5 inches, which is WRONG. A foot = 12 inches)\n",
    "4. Inconsistent data (e.g., mixing up units, some data captured as cm instead of inches)\n",
    "\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "## TIDINESS\n",
    "1. Combine all seperated tables, join by ```tweet_id```\n",
    "\n",
    "2. df_twitter drop column ```full_text``` because it contains multiple observational units (e.g., name, url, score, etc.)\n",
    "\n",
    "*At least eight (8) data quality issues and two (2) tidiness issues are detected, and include the issues to clean to satisfy the Project Motivation. Each issue is documented in one to a few sentences each.*\n",
    "    \n",
    "**Tips for Tidying**\n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table\n",
    "*Reference for [tidy data here](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)*\n",
    "    \n",
    "## FEATURE ENGINEEERING\n",
    "1. df_archive\n",
    "    * create a percentage column of the numerator and denometer ratings\n",
    "    * create column for twitter-web vs twitter-phone vs twitter-tweetdeck vs vine source\n",
    "    * create a column for \"bonus\" for any ratings that exceed score of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='clean'></a>\n",
    "# 3. CLEANING DATA\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**3.1 CRITERIA:** The student uses the steps in the data cleaning process to guide their cleaning efforts.\n",
    "\n",
    "**3.1 SPECIFICATION:**\n",
    "The define, code, and test steps of the cleaning process are clearly documented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**3.2 CRITERIA:** The student is able to thoroughly clean a dataset programmatically.\n",
    "\n",
    "**3.2 SPECIFICATION:**\n",
    "\n",
    "Copies of the original pieces of data are made prior to cleaning.\n",
    "\n",
    "All issues identified in the assess phase are successfully cleaned (if possible) using Python and pandas, and include the cleaning tasks required to satisfy the Project Motivation.\n",
    "\n",
    "A tidy master dataset (or datasets, if appropriate) with all pieces of gathered data is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='store'></a>\n",
    "# 4. STORING AND ACTING ON WRANGLED DATA\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**4.1 CRITERIA:** The student is able to store a gathered, assessed, and cleaned dataset.\n",
    "\n",
    "**4.1 SPECIFICATION:**\n",
    "\n",
    "Students will save their gathered, assessed, and cleaned master dataset(s) to a CSV file or a SQLite database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**4.2 CRITERIA:** The student is able to act on their wrangled data to produce insights (e.g. analyses, visualizations, and/or models).\n",
    "\n",
    "**4.2 SPECIFICATION:**\n",
    "\n",
    "The master dataset is analyzed using pandas or SQL in the Jupyter Notebook and at least three (3) separate insights are produced.\n",
    "\n",
    "At least one (1) labeled visualization is produced in the Jupyter Notebook using Python’s plotting libraries or in Tableau.\n",
    "\n",
    "Students must make it clear in their wrangling work that they assessed and cleaned (if necessary) the data upon which the analyses and visualizations are based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='report'></a>\n",
    "# 5. REPORT-DISCUSSION-CONCLUSION\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**5.1 CRITERIA:** The student is able to reflect upon and describe their data wrangling efforts.\n",
    "\n",
    "**5.1 SPECIFICATION:**\n",
    "\n",
    "The student’s wrangling efforts are briefly described. This document (wrangle_report.pdf or wrangle_report.html) is concise and approximately 300-600 words in length.\n",
    "\n",
    "At least one (1) labeled visualization is produced in the Jupyter Notebook using Python’s plotting libraries or in Tableau.\n",
    "\n",
    "Students must make it clear in their wrangling work that they assessed and cleaned (if necessary) the data upon which the analyses and visualizations are based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**5.2 CRITERIA:** The student is able to describe some insights found in their wrangled dataset.\n",
    "\n",
    "**5.2 SPECIFICATION:**\n",
    "\n",
    "The three (3) or more insights the student found are communicated. At least one (1) visualization is included.\n",
    "\n",
    "This document (act_report.pdf or act_report.html) is at least 250 words in length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>\n",
    "\n",
    "<a id='files'></a>\n",
    "# 6. PROJECT FILES\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "**6.1 CRITERIA:** Are all required files included in the student's submission?\n",
    "\n",
    "**6.1 SPECIFICATION:**\n",
    "The following files (with identical filenames) are included:\n",
    "\n",
    "* wrangle_act.ipynb\n",
    "* wrangle_report.pdf or wrangle_report.html\n",
    "* act_report.pdf or act_report.html\n",
    "    \n",
    "All dataset files are included, including the stored master dataset(s), with filenames and extensions as specified on the Project Submission page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr size=\"5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Data Project!\n",
    "\n",
    "Made with ❤️ by Jhon!\n",
    "\n",
    "<a href=\"#contents\">[Table of Contents]</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
